{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3254,
     "status": "ok",
     "timestamp": 1604647140528,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "GUwDeFerT89A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, auc, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2599,
     "status": "ok",
     "timestamp": 1604647140534,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "m8PPhH8ICLaP",
    "outputId": "0d3ad4f2-8dd6-4543-b4c7-4722088f5703"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1950,
     "status": "ok",
     "timestamp": 1604647140539,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "ZihHfS_LT64t"
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from config import device, is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N62ZZGeoT644"
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1604647146335,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "goCLd4xXT644"
   },
   "outputs": [],
   "source": [
    "class QAMatchDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_seq_len_q, max_seq_len_r, mode):\n",
    "        assert mode in ['train', 'dev', 'test']\n",
    "\n",
    "        self.mode = mode\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.max_seq_len_q = max_seq_len_q\n",
    "        self.max_seq_len_r = max_seq_len_r\n",
    "        # self.df = pd.read_csv(file)\n",
    "        # self.seqs, self.seq_masks, self.seq_segments, self.labels = self.get_input(file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        token_seq_1 = self.df.iloc[idx]['question']\n",
    "        token_seq_2 = self.df.iloc[idx]['reply_content']\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            label_tensor = torch.tensor(self.df.iloc[idx]['label'])\n",
    "        else:\n",
    "            label_tensor = None\n",
    "        token_seq_1 = self.tokenizer.tokenize(token_seq_1)\n",
    "        token_seq_2 = self.tokenizer.tokenize(token_seq_2)\n",
    "#         print(\"token_seq_1:\", token_seq_1, \"lens:\", len(token_seq_1))\n",
    "#         print(\"token_seq_2:\", token_seq_2, \"lens:\", len(token_seq_2))\n",
    "\n",
    "        # truncate\n",
    "        if len(token_seq_1) > self.max_seq_len_q:\n",
    "            token_seq_1 = token_seq_1[:self.max_seq_len_q]\n",
    "        if len(token_seq_2) > self.max_seq_len_r:\n",
    "            token_seq_2 = token_seq_2[:self.max_seq_len_r]\n",
    "\n",
    "        seq = [\"[CLS]\"] + token_seq_1 + [\"[SEP]\"] + token_seq_2 + [\"[SEP]\"]\n",
    "        seq = self.tokenizer.convert_tokens_to_ids(seq)\n",
    "\n",
    "        seq_segments = [0] * (len(token_seq_1) + 2) + [1] * (len(token_seq_2) + 1)\n",
    "\n",
    "        return torch.Tensor(seq).type(torch.long), torch.Tensor(seq_segments).type(torch.long), \\\n",
    "            torch.Tensor([len(token_seq_1), len(token_seq_2)]).type(torch.long), label_tensor\n",
    "            \n",
    "\n",
    "    def collate_fn(self, samples):\n",
    "        seqs = [s[0] for s in samples]\n",
    "        seq_segments = [s[1] for s in samples]\n",
    "        seq_lens = torch.stack([s[2] for s in samples])\n",
    "\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            labels = torch.stack([s[3] for s in samples])\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        seqs = pad_sequence(seqs, batch_first=True)\n",
    "        seq_segments = pad_sequence(seq_segments, batch_first=True)\n",
    "\n",
    "        # attention mask处理\n",
    "        seq_masks = torch.zeros(seqs.shape, dtype=torch.long)\n",
    "        seq_masks = seq_masks.masked_fill(seqs != 0, 1)\n",
    "\n",
    "        return seqs, seq_masks, seq_segments, seq_lens, labels\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcQmyLC8T647"
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1604647147355,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "YInuSpqWT648"
   },
   "outputs": [],
   "source": [
    "class BertModelTrain(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(BertModelTrain, self).__init__()        \n",
    "        self.bert_config = BertConfig.from_pretrained(os.path.join(params['pretrained_model_path'], 'config.json'))\n",
    "        self.bert = BertModel.from_pretrained(params['pretrained_model_path'], output_hidden_states=True)\n",
    "        self.linear = nn.Linear(15*self.bert_config.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(p=params['dropout_rate'])\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True     # fine-tune，每个参数都要更新\n",
    "\n",
    "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, batch_seq_lens, labels=None):\n",
    "        \"\"\"\n",
    "        :param batch_seqs: input_ids\n",
    "        :param batch_seq_masks: attention_mask\n",
    "        :param batch_seq_segments: token_type_ids\n",
    "        :param batch_seq_lens: (batch, 2)   记录着每一个样本对中，两个文本的真实长度（即不加[CLS]/[SEP]）\n",
    "        :param labels:\n",
    "        :return: outputs: (loss, logits, ...)\n",
    "                 outputs: (logits, ...)\n",
    "        \"\"\"\n",
    "        # q_embeddings: last_hidden_state, (batch_size, sequence_length, hidden_size)\n",
    "        # pooler_output : 最后一层[CLS]token的hidden state过一个FN+tanh输出的logits  (batch_size, hidden_size)\n",
    "        # hidden_states : 每一层的sequence output: (input, layer1, layer2, ..., layer11, layer12)，其中每个的shape: (batch_size, hidden_state)\n",
    "        q_embeddings, pooler_output, hidden_states = self.bert(input_ids=batch_seqs,\n",
    "                                                               attention_mask=batch_seq_masks,\n",
    "                                                               token_type_ids=batch_seq_segments)[:3]\n",
    "        # 倒数第二层的sequence output\n",
    "        lbo_embeddings = hidden_states[-2] \n",
    "        # 倒数第三层的sequence output\n",
    "        ltl_embeddings = hidden_states[-3] \n",
    "        # last layer cls hidden state: (batch_size, hidden_size)\n",
    "        last_cls_hidden_state = q_embeddings[:, 0]\n",
    "        # last but one layer cls hidden state : (batch_size, hidden_size)\n",
    "        lbo_cls_hidden_state = lbo_embeddings[:, 0]\n",
    "        \n",
    "        # 倒数第一层：seq_1和seq_2的句向量embedding（max pooling），均是(batch, hidden_size)\n",
    "        last_seq_1_embeddings, last_seq_2_embeddings = self.get_seq_embeddings(q_embeddings, batch_seq_lens)\n",
    "        # |seq_1 - seq_2|\n",
    "        last_seq_gap = torch.abs(last_seq_1_embeddings - last_seq_2_embeddings)\n",
    "        # seq_1 * seq_2 （对应维度相乘）\n",
    "        last_seq_multiple = last_seq_1_embeddings * last_seq_2_embeddings\n",
    "        \n",
    "        \n",
    "        # 倒数第二层, last but one layer\n",
    "        lbo_seq_1_embeddings, lbo_seq_2_embeddings = self.get_seq_embeddings(lbo_embeddings, batch_seq_lens)\n",
    "        # |seq_1 - seq_2|\n",
    "        lbo_seq_gap = torch.abs(lbo_seq_1_embeddings - lbo_seq_2_embeddings)\n",
    "        # seq_1 * seq_2 （对应维度相乘）\n",
    "        lbo_seq_multiple = lbo_seq_1_embeddings * lbo_seq_2_embeddings\n",
    "        \n",
    "        # 倒数第三层, last third layer\n",
    "        ltl_seq_1_embeddings, ltl_seq_2_embeddings = self.get_seq_embeddings(ltl_embeddings, batch_seq_lens)\n",
    "        # |seq_1 - seq_2|\n",
    "        ltl_seq_gap = torch.abs(ltl_seq_1_embeddings - ltl_seq_2_embeddings)\n",
    "        # seq_1 * seq_2 （对应维度相乘）\n",
    "        ltl_seq_multiple = ltl_seq_1_embeddings * ltl_seq_2_embeddings\n",
    "        \n",
    "        \n",
    "        # concatenate this four tensor -> (batch_size, 15*hidden_size)\n",
    "        x = torch.cat([pooler_output, last_cls_hidden_state, lbo_cls_hidden_state, \n",
    "                       last_seq_1_embeddings, last_seq_gap, last_seq_multiple, last_seq_2_embeddings, \n",
    "                       lbo_seq_1_embeddings, lbo_seq_gap, lbo_seq_multiple, lbo_seq_2_embeddings,\n",
    "                       ltl_seq_1_embeddings, ltl_seq_gap, ltl_seq_multiple, ltl_seq_2_embeddings], dim=1)\n",
    "\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "        # FC层 -> (batch, 1)\n",
    "        x = self.linear(x)\n",
    "        # sigmoid\n",
    "        output = torch.sigmoid(x)    # (batch_size, 1) 即模型预测每个样本为1的概率\n",
    "\n",
    "        logits = x\n",
    "        proba_0 = 1.0 - output     # (batch_size, 1)\n",
    "        probabilities = torch.cat((proba_0, output), dim=1)   # (batch_size, 2)\n",
    "        if labels is not None:\n",
    "            # 有标签，则返回loss, logits, probabilities\n",
    "            loss = self.loss_fn(output.squeeze(1), labels.type(torch.float))\n",
    "            outputs = (loss, logits, probabilities)\n",
    "        else:\n",
    "            # 无标签，则返回logits, probabilities\n",
    "            outputs = (logits, probabilities)\n",
    "\n",
    "        return outputs\n",
    "    def get_seq_embeddings(self, q_embeddings, batch_seq_lens):\n",
    "        \"\"\"\n",
    "        获取batch中每个样本对中，seq_1和seq_2的\n",
    "        :param q_embeddings: last_hidden_state, (batch_size, sequence_length, hidden_size)\n",
    "        :param batch_seq_lens: (batch, 2)   记录着每一个样本对中，两个文本的真实长度（即不加[CLS]/[SEP]）\n",
    "        \"\"\"\n",
    "        batch_seq_1 = []\n",
    "        batch_seq_2 = []\n",
    "        for batch in range(q_embeddings.shape[0]):\n",
    "            seq_1_end_index = 1 + batch_seq_lens[batch][0]     # # 要加1，否则最后一个字取不到。这里不包含第一句的[SEP]\n",
    "            seq_2_start_index = seq_1_end_index + 1\n",
    "            seq_2_end_index = seq_2_start_index + batch_seq_lens[batch][1]   # 第二句不包括最后的[SEP]\n",
    "            seq_1_embedding = q_embeddings[batch, 1:seq_1_end_index,:]\n",
    "            seq_2_embedding = q_embeddings[batch, seq_2_start_index:seq_2_end_index,:]\n",
    "            batch_seq_1.append(torch.max(seq_1_embedding, dim=0)[0])\n",
    "            batch_seq_2.append(torch.max(seq_2_embedding, dim=0)[0])\n",
    "        batch_seq_1 = torch.stack(batch_seq_1)\n",
    "        batch_seq_2 = torch.stack(batch_seq_2)\n",
    "        return batch_seq_1.to(device), batch_seq_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToLog(path, content):\n",
    "    with open(path, 'a') as fp:\n",
    "        fp.write(content)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCGlq6qBT64_"
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1501,
     "status": "ok",
     "timestamp": 1604647152153,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "feiElGnzT65B"
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, dev_dataloader, params, bert_tokenizer, best_model_path, output_path, fold,\n",
    "          version, checkpoint=None):\n",
    "    # ---------------------- Model definition ---------------------- #\n",
    "    print(\"\\t* Building model...\")\n",
    "    bulid_time = time.time()\n",
    "    model = BertModelTrain(params).to(device)\n",
    "    print(\"\\t* Building model time:{:.4f}s\".format(time.time()-bulid_time))\n",
    "    # ---------------------- Preparation for training -------------- #\n",
    "#     param_optimizer = list(model.named_parameters())\n",
    "    # 这里，指定部分参数不参与权重衰减\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "#     optimizer_grouped_parameters = [{\n",
    "#         'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "#         'weight_decay': params['weight_decay']\n",
    "#     }, {\n",
    "#         'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "#         'weight_decay': 0.0\n",
    "#     }]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': params['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "#     optimizer = AdamW(optimizer_grouped_parameters, lr=params['lr'])\n",
    "    optimizer = Adam(model.parameters(), lr=params['lr'])\n",
    "#     optimizer = SGD(model.parameters(),lr=params['lr'],momentum=params['momentum'], weight_decay=params['l2_weight'])\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.85, patience=params['patience'])\n",
    "    num_training_steps = len(train_dataloader) * params['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_training_steps)\n",
    "\n",
    "    best_score = 0.0    # 记录validation最好的结果\n",
    "    best_thres = 0.0\n",
    "    start_epoch = 1\n",
    "    # Data for loss curves plot\n",
    "    epoch_count = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_f1s = []\n",
    "    valid_f1s = []\n",
    "    train_aucs = []\n",
    "    valid_aucs = []\n",
    "    best_model_saved_path = os.path.join(best_model_path, 'best-fine-tune-'+version+'-k'+str(fold)+'.bin')\n",
    "\n",
    "    # Compute loss and accuracy before starting (or resuming) training\n",
    "    # 如果准备start training，这里的valid结果就是预训练BERT（做fine-tune之前）对下游任务的效果\n",
    "    # 如果准备resuming training，这里的valid结果就是上一次fine-tune的结果\n",
    "    valid_loss, valid_accuracy, valid_f1, valid_auc, thres = validate(model, dev_dataloader)\n",
    "    print(\"\\t* Validation loss before training: {:.4f}, accuracy:{:.4f}, \"\n",
    "          \"f1_score: {:.4f}, best_thres: {:.4f}, auc: {:.4f}\".\n",
    "          format(valid_loss, (valid_accuracy * 100), valid_f1, thres, valid_auc))\n",
    "    print(\"\\n\", 20 * \"=\", \"Training Bert model o device: {}\".format(device), 20 * \"=\")\n",
    "\n",
    "    patience_counter = 0\n",
    "    for epoch in range(start_epoch, params['epochs']+1):\n",
    "        print(\"-> Start epoch {}\".format(epoch))\n",
    "        writeToLog(output_path, \"-> Start epoch {}\".format(epoch))\n",
    "        epoch_count.append(epoch)\n",
    "        # train\n",
    "        epoch_time, epoch_loss, epoch_accuracy, epoch_f1, epoch_auc = train_for_one_epoch(model,\n",
    "                                                                                          train_dataloader,\n",
    "                                                                                          optimizer,\n",
    "                                                                                          scheduler,\n",
    "                                                                                          params['max_gradient_norm'])\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_f1s.append(epoch_f1)\n",
    "        train_aucs.append(epoch_auc)\n",
    "        print(\"-> Training time:{:.4f}s, loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, auc: {:.4f}\".\n",
    "              format(epoch_time, epoch_loss, epoch_accuracy*100, epoch_f1, epoch_auc))\n",
    "        writeToLog(output_path, \"-> Training time:{:.4f}s, loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, auc: {:.4f}\".\n",
    "              format(epoch_time, epoch_loss, epoch_accuracy*100, epoch_f1, epoch_auc))\n",
    "        \n",
    "        # validation\n",
    "        valid_loss, valid_accuracy, valid_f1, valid_auc, thres = validate(model, dev_dataloader)\n",
    "        print(\"-> Validation loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, best_thres: {:.4f}, auc: {:.4f}\".\n",
    "              format(valid_loss, valid_accuracy * 100, valid_f1, thres, valid_auc))\n",
    "        writeToLog(output_path, \"-> Validation loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, best_thres: {:.4f}, auc: {:.4f}\".\n",
    "              format(valid_loss, valid_accuracy * 100, valid_f1, thres, valid_auc))\n",
    "        \n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_f1s.append(valid_f1)\n",
    "        valid_aucs.append(valid_auc)\n",
    "#         scheduler.step(valid_loss)\n",
    "        \n",
    "        if valid_auc <= best_score:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            best_score = valid_auc\n",
    "            best_thres = thres\n",
    "            patience_counter = 0\n",
    "            best_model_saved_path = os.path.join(best_model_path, 'best-fine-tune-'+version+'-k'+str(fold)+'.bin')\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"best_score\": best_score,    # k fold时以valid auc来看每折的模型的能力，从而对最终的预测结果进行加权平均\n",
    "                \"best_thres\": best_thres,\n",
    "                \"epochs_count\": epoch_count,\n",
    "                \"train_losses\": train_losses,\n",
    "                \"valid_losses\": valid_losses\n",
    "            }, best_model_saved_path)\n",
    "\n",
    "        if patience_counter >= params['early_stoping']:\n",
    "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "            break\n",
    "            \n",
    "    if patience_counter != 0:\n",
    "        # 如果最后一个epoch不是最好的模型，则读取之前的最好的模型\n",
    "        best_checkpoint = torch.load(best_model_saved_path)\n",
    "        model.load_state_dict(best_checkpoint['model'])\n",
    "#     return model, best_score, epoch_count, train_losses, train_f1s, train_aucs, valid_losses, valid_f1s, valid_aucs\n",
    "    return model, best_score\n",
    "\n",
    "\n",
    "def train_for_one_epoch(model, dataloader, optimizer, scheduler, max_gradient_norm):\n",
    "    model.train()\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0   # 记录整个epoch的累加loss\n",
    "    correct_count = 0.0\n",
    "    batch_avg_time = 0.0 # 记录该epoch平均batch花费时间\n",
    "    all_preds = []\n",
    "    all_pred_probas = []\n",
    "    all_labels = []\n",
    "\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    for batch_index, data in enumerate(tqdm_dataloader):\n",
    "        batch_start_time = time.time()\n",
    "        if is_cuda:\n",
    "            data = [t.to(device) for t in data if t is not None]\n",
    "        # 梯度置零\n",
    "        optimizer.zero_grad()\n",
    "        seqs, seq_masks, seq_segments, seq_lens, labels = data\n",
    "        outputs = model(seqs, seq_masks, seq_segments, seq_lens, labels)\n",
    "        # 回传梯度\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        probabilities = outputs[2]\n",
    "        # probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        loss.backward()\n",
    "        # 梯度裁剪\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = torch.argmax(probabilities, dim=1)\n",
    "        correct_count = correct_count + (pred == labels).sum().item()\n",
    "        batch_avg_time += time.time() - batch_start_time\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_pred_probas.append(probabilities.detach().cpu())\n",
    "\n",
    "        description = \"Batch num: {}. Avg. batch proc. time: {:.4f}s, loss: {:.4f}\".\\\n",
    "            format(batch_index+1, batch_avg_time/(batch_index+1), running_loss/(batch_index+1))\n",
    "        tqdm_dataloader.set_description(description)\n",
    "#         del data\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "    all_labels = torch.cat(all_labels)    # 把每个batch的labels平铺成一维tensor (samples, )\n",
    "    all_preds = torch.cat(all_preds)      # 把每个batch的preds平铺成一维tensor (samples, )\n",
    "    all_pred_probas = torch.cat(all_pred_probas) # 把每个batch的probas平铺成tensor (samples, 2)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_pred_probas[:, 1], pos_label=1)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_count / len(dataloader.dataset)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    epoch_auc = auc(fpr, tpr)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    return epoch_time, epoch_loss, epoch_accuracy, epoch_f1, epoch_auc\n",
    "#     return epoch_time, epoch_loss, epoch_accuracy, 0, epoch_auc\n",
    "\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0  # 记录整个epoch的累加loss\n",
    "    correct_count = 0.0\n",
    "    # all_preds = []\n",
    "    all_labels = []\n",
    "    all_pred_probas = []\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "\n",
    "    # Deactivate autograd for evaluation\n",
    "    with torch.no_grad():   # 必须加这个，减少显存的使用\n",
    "        for batch_index, data in enumerate(tqdm_dataloader):\n",
    "            if is_cuda:\n",
    "                data = [t.to(device) for t in data if t is not None]\n",
    "\n",
    "            seqs, seq_masks, seq_segments, seq_lens, labels = data\n",
    "            outputs = model(seqs, seq_masks, seq_segments, seq_lens, labels)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            probabilities = outputs[2]\n",
    "            # probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # _, pred = torch.max(logits, dim=1)\n",
    "\n",
    "            # correct_count = correct_count + (pred == labels).sum().item()\n",
    "            # all_preds.append(pred.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_pred_probas.append(probabilities.cpu())\n",
    "            \n",
    "#             del data\n",
    "#             torch.cuda.empty_cache()\n",
    "                    \n",
    "    all_labels = torch.cat(all_labels)  # 把每个batch的labels平铺成一维tensor shape: (samples, )\n",
    "    # all_preds = torch.cat(all_preds)  # 把每个batch的preds平铺成一维tensor shape: (samples, )\n",
    "    all_pred_probas = torch.cat(all_pred_probas)  # 把每个batch的probas变成tensor（原来是[tensor, tensor, ...]）\n",
    "\n",
    "\n",
    "    # best_f1, best_thres = search_f1(all_labels, all_pred_probas[:, 1])\n",
    "    # all_preds = (all_pred_probas[:, 1] > best_thres).type(torch.long)\n",
    "    all_preds = torch.argmax(all_pred_probas, dim=1)\n",
    "    correct_count = (all_preds == all_labels).sum().item()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_pred_probas[:, 1], pos_label=1)\n",
    "\n",
    "    valid_loss = running_loss / len(dataloader)\n",
    "    valid_acc = correct_count / len(dataloader.dataset)\n",
    "    valid_f1 = f1_score(all_labels, all_preds)\n",
    "    # valid_f1 = best_f1\n",
    "    valid_auc = auc(fpr, tpr)\n",
    "    best_thres = 0\n",
    "    return valid_loss, valid_acc, valid_f1, valid_auc, best_thres\n",
    "    # return valid_loss, valid_acc, 0, 0\n",
    "    \n",
    "def search_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_true: 一维tensor\n",
    "    :param y_pred: 一维tensor，y_pred[i]表示第i个样本在label为1上的预测概率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    best_score = 0.0\n",
    "    best_thres = 0.0\n",
    "    for i in range(30, 70):\n",
    "        thres = i / 100\n",
    "        y_pred_bin = (y_pred > thres)   # 大于thres的为1，小于thres的为0\n",
    "        # print(\"y_pred_bin shape:\", y_pred_bin.shape)\n",
    "        score = f1_score(y_true, y_pred_bin)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thres = thres\n",
    "\n",
    "    return best_score, best_thres\n",
    "    \n",
    "def get_pred_probas(model, dataloader, is_test=False):\n",
    "    model.eval()\n",
    "    probas = None\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            # 将所有tensors移到GPU上\n",
    "            if is_cuda:\n",
    "                data = [t.to(device) for t in data if t is not None]\n",
    "                \n",
    "            if is_test:\n",
    "                seqs, seq_masks, seq_segments, seq_lens = data[:4]\n",
    "            else:\n",
    "                seqs, seq_masks, seq_segments, seq_lens, labels = data\n",
    "                all_labels.append(labels)\n",
    "            outputs = model(seqs,\n",
    "                            seq_masks,\n",
    "                            seq_segments,\n",
    "                            seq_lens)\n",
    "            logits = outputs[0]\n",
    "            probabilities = outputs[1]   # (batch, 2)\n",
    "\n",
    "            if probas is None:\n",
    "                probas = probabilities\n",
    "            else:\n",
    "                # 将每个batch的预测结果拼接起来\n",
    "                probas = torch.cat([probas, probabilities])\n",
    "    if is_test:\n",
    "        return probas.cpu()\n",
    "    all_labels = torch.cat(all_labels)  # (len, )\n",
    "    return probas.cpu(), all_labels.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPlXyVxaT65G"
   },
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1604647152686,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "bPHMPZyOT65H"
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_val(train_df, test_df, params, k, bert_tokenizer, best_model_path, output_path, version):\n",
    "    kf = KFold(n_splits=k)\n",
    "    test_dataset = QAMatchDataset(test_df, bert_tokenizer, params['max_seq_len_q'], params['max_seq_len_r'], mode='test')\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=256, num_workers=3, collate_fn=test_dataset.collate_fn)\n",
    "    dev_labels = []\n",
    "    dev_probas = []\n",
    "    k_test_probas = []\n",
    "    k_best_scores = []\n",
    "    for fold, (train_idxs, dev_idxs) in enumerate(kf.split(train_df)):\n",
    "        print(\"\\t* Start \"+str(fold)+\" fold\")\n",
    "        writeToLog(output_path, \"\\t* Start \"+str(fold)+\" fold\")\n",
    "#         dev_labels.extend(train_df.iloc[dev_idxs]['label'].tolist())\n",
    "        # ---------------------- Data loading -------------------------- #\n",
    "        print(\"\\t* Building dataset...\")\n",
    "        train_dataset = QAMatchDataset(train_df.iloc[train_idxs], bert_tokenizer, params['max_seq_len_q'], params['max_seq_len_r'], 'train')\n",
    "        dev_dataset = QAMatchDataset(train_df.iloc[dev_idxs], bert_tokenizer, params['max_seq_len_q'], params['max_seq_len_r'], 'dev')\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'], num_workers=3,\n",
    "                                      collate_fn=train_dataset.collate_fn)\n",
    "        dev_dataloader = DataLoader(dev_dataset, batch_size=256, num_workers=3,\n",
    "                                    collate_fn=dev_dataset.collate_fn)\n",
    "        best_model_fold_path = os.path.join(best_model_path, 'best-fine-tune-'+version+'-k'+str(fold)+'.bin')\n",
    "        checkpoint = None\n",
    "        if not(os.path.exists(best_model_fold_path)):\n",
    "            # 若没有\n",
    "            \n",
    "            model, best_score = train(train_dataloader, dev_dataloader, params, bert_tokenizer, best_model_path, output_path, \n",
    "                                      fold, version, checkpoint=None)\n",
    "        else:\n",
    "            checkpoint = torch.load(best_model_fold_path)\n",
    "            model = BertModelTrain(params).to(device)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            best_score = checkpoint['best_score']\n",
    "        k_best_scores.append(best_score)\n",
    "        \n",
    "        fold_dev_proba, dev_label = get_pred_probas(model, dev_dataloader)\n",
    "        for idx, proba in zip(dev_idxs, fold_dev_proba):\n",
    "            train_df.loc[idx, 'proba_0'] = proba[0].item()\n",
    "            train_df.loc[idx, 'proba_1'] = proba[1].item()\n",
    "        fold_test_proba = get_pred_probas(model, test_dataloader, is_test=True)\n",
    "        \n",
    "        dev_labels.append(dev_label)\n",
    "        dev_probas.append(fold_dev_proba)  # (k, len(dev_idxs), 2)\n",
    "        k_test_probas.append(fold_test_proba) # (k, len(test_dataset), 2)\n",
    "#         model.to(torch.device('cpu'))\n",
    "        del model, train_dataloader, dev_dataloader, checkpoint\n",
    "        torch.cuda.empty_cache() \n",
    "        time.sleep(5)\n",
    "    \n",
    "    dev_labels = torch.cat(dev_labels)  # (len(train_df),)      # 把每一折的验证集的label拼接，得到整个训练集的label\n",
    "    dev_probas = torch.cat(dev_probas)  # (len(train_df), 2)    # 把每一折的验证集的预测结果拼接，得到整个训练集的预测结果\n",
    "    \n",
    "    k_test_probas = torch.stack(k_test_probas) # (k, len(test_dataset), 2)， 只是把[tensor, tensor, ... ]转为tensor\n",
    "#     test_probas = torch.mean(k_test_probas, dim=0)  # (len(test_dataset), 2)  取每一折的平均\n",
    "\n",
    "    # k折模型加权融合\n",
    "    k_best_scores = np.array(k_best_scores)              \n",
    "    k_weights = k_best_scores / k_best_scores.sum()             # (k,)\n",
    "    k_weights = np.expand_dims(np.expand_dims(k_weights,1),1)   # (k, 1, 1)\n",
    "    print('k_best_score :', k_best_scores)\n",
    "    print('k weights :', k_weights)\n",
    "    k_test_probas = k_test_probas * k_weights               # 广播机制，使得每个模型预测的概率乘上该模型的权重 (k, len(test_dataset), 2)\n",
    "    test_probas = torch.sum(k_test_probas, dim=0)           # 求和\n",
    "    # search f1\n",
    "    best_f1, best_thres = search_f1(dev_labels, dev_probas[:, 1])\n",
    "    print(best_f1, best_thres)\n",
    "    test_preds = (test_probas[:, 1] > best_thres).type(torch.long)\n",
    "    \n",
    "    # 不用search f1\n",
    "    # test_preds = torch.argmax(test_probas, dim=1) \n",
    "    return test_preds, k_test_probas, dev_probas, dev_labels, best_f1, best_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kf4-Fr6T65Y"
   },
   "source": [
    "## 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qs0l9xpYT65Y",
    "outputId": "817beebe-3e63-4b30-ccc9-1b73ee5458f7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* K fold training and validating...\n",
      "\t* Start 0 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:10.8502s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.05s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 0.9159, accuracy:75.5733, f1_score: 0.0000, best_thres: 0.0000, auc: 0.5303\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3653s, loss: 0.3947: 100%|██████████| 1439/1439 [08:51<00:00,  2.87it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:531.1643s, loss: 0.3947, accuracy: 84.3053%, f1_score: 0.6584, auc: 0.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2878, accuracy: 87.8504%, f1_score: 0.7589, best_thres: 0.0000, auc: 0.9320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3635s, loss: 0.2434: 100%|██████████| 1439/1439 [08:48<00:00,  2.88it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:528.7234s, loss: 0.2434, accuracy: 90.4732%, f1_score: 0.8056, auc: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2707, accuracy: 89.1707%, f1_score: 0.7873, best_thres: 0.0000, auc: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3625s, loss: 0.1566: 100%|██████████| 1439/1439 [08:47<00:00,  2.88it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:527.2816s, loss: 0.1566, accuracy: 94.0464%, f1_score: 0.8811, auc: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2930, accuracy: 90.0162%, f1_score: 0.8103, best_thres: 0.0000, auc: 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3600s, loss: 0.0978: 100%|██████████| 1439/1439 [08:43<00:00,  2.76it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:523.6300s, loss: 0.0978, accuracy: 96.5831%, f1_score: 0.9321, auc: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2924, accuracy: 91.2555%, f1_score: 0.8219, best_thres: 0.0000, auc: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3580s, loss: 0.0650: 100%|██████████| 1439/1439 [08:40<00:00,  2.84it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:520.9857s, loss: 0.0650, accuracy: 97.7529%, f1_score: 0.9554, auc: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.07s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3505, accuracy: 91.4871%, f1_score: 0.8300, best_thres: 0.0000, auc: 0.9513\n",
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3583s, loss: 0.0451: 100%|██████████| 1439/1439 [08:41<00:00,  2.95it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:521.2943s, loss: 0.0451, accuracy: 98.5116%, f1_score: 0.9704, auc: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.07s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4045, accuracy: 91.2671%, f1_score: 0.8290, best_thres: 0.0000, auc: 0.9498\n",
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3595s, loss: 0.0370: 100%|██████████| 1439/1439 [08:43<00:00,  2.80it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:523.3577s, loss: 0.0370, accuracy: 98.7954%, f1_score: 0.9761, auc: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4134, accuracy: 91.2439%, f1_score: 0.8283, best_thres: 0.0000, auc: 0.9491\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 1 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:6.8662s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.07s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 1.8544, accuracy:24.4962, f1_score: 0.3935, best_thres: 0.0000, auc: 0.4698\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3673s, loss: 0.4014: 100%|██████████| 1439/1439 [08:54<00:00,  2.81it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:534.4626s, loss: 0.4014, accuracy: 84.1634%, f1_score: 0.6644, auc: 0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2804, accuracy: 88.7074%, f1_score: 0.7662, best_thres: 0.0000, auc: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3679s, loss: 0.2241: 100%|██████████| 1439/1439 [08:55<00:00,  2.91it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:535.4907s, loss: 0.2241, accuracy: 91.2463%, f1_score: 0.8223, auc: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3068, accuracy: 89.2865%, f1_score: 0.7840, best_thres: 0.0000, auc: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3676s, loss: 0.1349: 100%|██████████| 1439/1439 [08:54<00:00,  2.84it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:535.0929s, loss: 0.1349, accuracy: 94.9904%, f1_score: 0.9004, auc: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3255, accuracy: 90.1668%, f1_score: 0.8042, best_thres: 0.0000, auc: 0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3650s, loss: 0.0890: 100%|██████████| 1439/1439 [08:51<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:531.4488s, loss: 0.0890, accuracy: 96.9016%, f1_score: 0.9385, auc: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3388, accuracy: 90.7691%, f1_score: 0.8142, best_thres: 0.0000, auc: 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3630s, loss: 0.0601: 100%|██████████| 1439/1439 [08:47<00:00,  2.83it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:528.0575s, loss: 0.0601, accuracy: 97.8948%, f1_score: 0.9583, auc: 0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3795, accuracy: 90.7691%, f1_score: 0.8142, best_thres: 0.0000, auc: 0.9442\n",
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3609s, loss: 0.0436: 100%|██████████| 1439/1439 [08:45<00:00,  2.95it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:525.2426s, loss: 0.0436, accuracy: 98.5319%, f1_score: 0.9708, auc: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4031, accuracy: 91.2208%, f1_score: 0.8280, best_thres: 0.0000, auc: 0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3618s, loss: 0.0340: 100%|██████████| 1439/1439 [08:46<00:00,  2.83it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:526.4853s, loss: 0.0340, accuracy: 98.8533%, f1_score: 0.9772, auc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3725, accuracy: 91.8925%, f1_score: 0.8359, best_thres: 0.0000, auc: 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3608s, loss: 0.0262: 100%|██████████| 1439/1439 [08:44<00:00,  2.81it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:525.0881s, loss: 0.0262, accuracy: 99.1371%, f1_score: 0.9828, auc: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.08s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4331, accuracy: 92.0315%, f1_score: 0.8354, best_thres: 0.0000, auc: 0.9537\n",
      "-> Start epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3646s, loss: 0.0221: 100%|██████████| 1439/1439 [08:50<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:530.6843s, loss: 0.0221, accuracy: 99.2819%, f1_score: 0.9857, auc: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4287, accuracy: 92.1821%, f1_score: 0.8426, best_thres: 0.0000, auc: 0.9562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3596s, loss: 0.0159: 100%|██████████| 1439/1439 [08:43<00:00,  2.79it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:523.6956s, loss: 0.0159, accuracy: 99.4209%, f1_score: 0.9885, auc: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4853, accuracy: 92.2284%, f1_score: 0.8407, best_thres: 0.0000, auc: 0.9503\n",
      "-> Start epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3622s, loss: 0.0125: 100%|██████████| 1439/1439 [08:47<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:527.3294s, loss: 0.0125, accuracy: 99.5280%, f1_score: 0.9906, auc: 0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.5320, accuracy: 92.4600%, f1_score: 0.8458, best_thres: 0.0000, auc: 0.9516\n",
      "-> Start epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3603s, loss: 0.0101: 100%|██████████| 1439/1439 [08:44<00:00,  2.86it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:524.6754s, loss: 0.0101, accuracy: 99.6091%, f1_score: 0.9922, auc: 0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:38<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.5356, accuracy: 92.4021%, f1_score: 0.8451, best_thres: 0.0000, auc: 0.9521\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 2 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:7.1827s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.06s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 4.7942, accuracy:25.1564, f1_score: 0.4020, best_thres: 0.0000, auc: 0.4466\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3657s, loss: 0.4335: 100%|██████████| 1439/1439 [08:52<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:532.3565s, loss: 0.4335, accuracy: 84.0331%, f1_score: 0.6638, auc: 0.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2726, accuracy: 89.0086%, f1_score: 0.7762, best_thres: 0.0000, auc: 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3645s, loss: 0.2249: 100%|██████████| 1439/1439 [08:50<00:00,  2.78it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:530.7317s, loss: 0.2249, accuracy: 91.2318%, f1_score: 0.8203, auc: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2870, accuracy: 89.8772%, f1_score: 0.8015, best_thres: 0.0000, auc: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3641s, loss: 0.1429: 100%|██████████| 1439/1439 [08:50<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:530.2088s, loss: 0.1429, accuracy: 94.7704%, f1_score: 0.8948, auc: 0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3172, accuracy: 90.5953%, f1_score: 0.8183, best_thres: 0.0000, auc: 0.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3652s, loss: 0.0938: 100%|██████████| 1439/1439 [08:51<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:531.7847s, loss: 0.0938, accuracy: 96.6526%, f1_score: 0.9328, auc: 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3300, accuracy: 90.6764%, f1_score: 0.8220, best_thres: 0.0000, auc: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3592s, loss: 0.0616: 100%|██████████| 1439/1439 [08:42<00:00,  2.94it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:523.0529s, loss: 0.0616, accuracy: 97.8514%, f1_score: 0.9569, auc: 0.9966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4166, accuracy: 91.1049%, f1_score: 0.8305, best_thres: 0.0000, auc: 0.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3600s, loss: 0.0475: 100%|██████████| 1439/1439 [08:44<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:524.2784s, loss: 0.0475, accuracy: 98.4247%, f1_score: 0.9684, auc: 0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3990, accuracy: 91.7420%, f1_score: 0.8385, best_thres: 0.0000, auc: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3582s, loss: 0.0369: 100%|██████████| 1439/1439 [08:41<00:00,  2.81it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:521.7450s, loss: 0.0369, accuracy: 98.8070%, f1_score: 0.9761, auc: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4535, accuracy: 91.0470%, f1_score: 0.8311, best_thres: 0.0000, auc: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3600s, loss: 0.0286: 100%|██████████| 1439/1439 [08:43<00:00,  2.86it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:523.8615s, loss: 0.0286, accuracy: 99.0502%, f1_score: 0.9810, auc: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.09s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4569, accuracy: 91.5566%, f1_score: 0.8325, best_thres: 0.0000, auc: 0.9517\n",
      "-> Start epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3591s, loss: 0.0233: 100%|██████████| 1439/1439 [08:42<00:00,  2.84it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:522.4740s, loss: 0.0233, accuracy: 99.2326%, f1_score: 0.9846, auc: 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.09s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.5053, accuracy: 92.1126%, f1_score: 0.8370, best_thres: 0.0000, auc: 0.9500\n",
      "-> Start epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3586s, loss: 0.0170: 100%|██████████| 1439/1439 [08:41<00:00,  2.87it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:521.7485s, loss: 0.0170, accuracy: 99.3861%, f1_score: 0.9877, auc: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:41<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.5397, accuracy: 92.2052%, f1_score: 0.8421, best_thres: 0.0000, auc: 0.9509\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 3 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:7.0599s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 1.2952, accuracy:74.8291, f1_score: 0.0000, best_thres: 0.0000, auc: 0.5518\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3660s, loss: 0.3929: 100%|██████████| 1439/1439 [08:52<00:00,  2.84it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:532.5552s, loss: 0.3929, accuracy: 84.1523%, f1_score: 0.6556, auc: 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2753, accuracy: 88.9494%, f1_score: 0.7841, best_thres: 0.0000, auc: 0.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3661s, loss: 0.2361: 100%|██████████| 1439/1439 [08:52<00:00,  2.86it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:532.5772s, loss: 0.2361, accuracy: 90.6037%, f1_score: 0.8077, auc: 0.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2823, accuracy: 89.6444%, f1_score: 0.8026, best_thres: 0.0000, auc: 0.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3639s, loss: 0.1432: 100%|██████████| 1439/1439 [08:49<00:00,  2.76it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:529.5446s, loss: 0.1432, accuracy: 94.6634%, f1_score: 0.8930, auc: 0.9827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3002, accuracy: 90.6521%, f1_score: 0.8183, best_thres: 0.0000, auc: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3616s, loss: 0.0908: 100%|██████████| 1439/1439 [08:46<00:00,  2.93it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:526.5880s, loss: 0.0908, accuracy: 96.7193%, f1_score: 0.9345, auc: 0.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3536, accuracy: 91.3935%, f1_score: 0.8290, best_thres: 0.0000, auc: 0.9493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3622s, loss: 0.0625: 100%|██████████| 1439/1439 [08:47<00:00,  2.82it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:527.3941s, loss: 0.0625, accuracy: 97.8457%, f1_score: 0.9569, auc: 0.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3660, accuracy: 91.6367%, f1_score: 0.8345, best_thres: 0.0000, auc: 0.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3637s, loss: 0.0457: 100%|██████████| 1439/1439 [08:49<00:00,  2.83it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:529.2730s, loss: 0.0457, accuracy: 98.4364%, f1_score: 0.9687, auc: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4155, accuracy: 91.6252%, f1_score: 0.8321, best_thres: 0.0000, auc: 0.9513\n",
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3612s, loss: 0.0349: 100%|██████████| 1439/1439 [08:45<00:00,  2.79it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:525.8468s, loss: 0.0349, accuracy: 98.8331%, f1_score: 0.9766, auc: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3890, accuracy: 91.8916%, f1_score: 0.8444, best_thres: 0.0000, auc: 0.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3607s, loss: 0.0289: 100%|██████████| 1439/1439 [08:45<00:00,  2.79it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:525.2496s, loss: 0.0289, accuracy: 99.0387%, f1_score: 0.9808, auc: 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4462, accuracy: 91.9263%, f1_score: 0.8421, best_thres: 0.0000, auc: 0.9531\n",
      "-> Start epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3610s, loss: 0.0216: 100%|██████████| 1439/1439 [08:45<00:00,  2.88it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:525.6216s, loss: 0.0216, accuracy: 99.2935%, f1_score: 0.9859, auc: 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4748, accuracy: 91.6367%, f1_score: 0.8369, best_thres: 0.0000, auc: 0.9511\n",
      "-> Start epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3595s, loss: 0.0166: 100%|██████████| 1439/1439 [08:42<00:00,  2.85it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:523.0601s, loss: 0.0166, accuracy: 99.4325%, f1_score: 0.9886, auc: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.5109, accuracy: 92.1464%, f1_score: 0.8429, best_thres: 0.0000, auc: 0.9513\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 4 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:7.2090s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.05s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 1.4945, accuracy:74.4585, f1_score: 0.0000, best_thres: 0.0000, auc: 0.5294\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3673s, loss: 0.3833: 100%|██████████| 1439/1439 [08:54<00:00,  2.61it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:534.3232s, loss: 0.3833, accuracy: 84.4824%, f1_score: 0.6600, auc: 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2831, accuracy: 88.7177%, f1_score: 0.7609, best_thres: 0.0000, auc: 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3656s, loss: 0.2400: 100%|██████████| 1439/1439 [08:51<00:00,  2.67it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:532.0178s, loss: 0.2400, accuracy: 90.5342%, f1_score: 0.8052, auc: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3050, accuracy: 89.1463%, f1_score: 0.7594, best_thres: 0.0000, auc: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3655s, loss: 0.1476: 100%|██████████| 1439/1439 [08:51<00:00,  2.77it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:531.8012s, loss: 0.1476, accuracy: 94.4202%, f1_score: 0.8872, auc: 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:39<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2846, accuracy: 90.9533%, f1_score: 0.8219, best_thres: 0.0000, auc: 0.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3631s, loss: 0.0934: 100%|██████████| 1439/1439 [08:48<00:00,  2.69it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:528.3225s, loss: 0.0934, accuracy: 96.6121%, f1_score: 0.9322, auc: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.03s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3454, accuracy: 90.8027%, f1_score: 0.8268, best_thres: 0.0000, auc: 0.9481\n",
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3626s, loss: 0.0610: 100%|██████████| 1439/1439 [08:47<00:00,  2.70it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:527.7138s, loss: 0.0610, accuracy: 97.8746%, f1_score: 0.9574, auc: 0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.06s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4040, accuracy: 90.7796%, f1_score: 0.8293, best_thres: 0.0000, auc: 0.9480\n",
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3611s, loss: 0.0462: 100%|██████████| 1439/1439 [08:45<00:00,  2.69it/s]\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:525.7449s, loss: 0.0462, accuracy: 98.4740%, f1_score: 0.9693, auc: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:40<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3713, accuracy: 91.0923%, f1_score: 0.8327, best_thres: 0.0000, auc: 0.9534\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "k_best_score : [0.95331582 0.95619852 0.95188428 0.95534269 0.95431516]\n",
      "k weights : [[[0.19981231]]\n",
      "\n",
      " [[0.20041652]]\n",
      "\n",
      " [[0.19951226]]\n",
      "\n",
      " [[0.20023714]]\n",
      "\n",
      " [[0.20002177]]]\n",
      "0.8331430137486867 0.53\n",
      "dev auc:  0.9491976911023325\n",
      "\t* Saving dev result...\n",
      "\t* Predicting...\n",
      "\t* Saving test result...\n"
     ]
    }
   ],
   "source": [
    "model_version = 'FFTPD-5fold-V4.8'     # 模型版本\n",
    "scheme_version = 'FFTPD-5fold-V4.8'     # 方案版本\n",
    "# train_df = pd.read_csv(train_all_path)\n",
    "train_df = pd.read_csv(config.augmented_V0204_path)\n",
    "# test_df = pd.read_csv(test_path)\n",
    "# train_df = pd.read_csv(train_V0_path)\n",
    "test_df = pd.read_csv(config.test_V0_path)\n",
    "k = 5\n",
    "\n",
    "params = {\n",
    "    'batch_size': 24,\n",
    "    'epochs': 15,\n",
    "    'lr': 2e-05,\n",
    "    'l2_weight':0,\n",
    "    'weight_decay': 0.01,\n",
    "    'dropout_rate': 0.5,\n",
    "    'early_stoping':3,\n",
    "    'patience': 2,\n",
    "    'max_seq_len_q': config.max_seq_len_q,\n",
    "    'max_seq_len_r': config.max_seq_len_r,\n",
    "    'max_gradient_norm': 10.0,\n",
    "    'pretrained_model_path': config.pretrained_roberta_wwm_ext_large_path, \n",
    "}\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(os.path.join(params['pretrained_model_path'], 'vocab.txt'))\n",
    "output_path = os.path.join(config.root_path, 'output/'+scheme_version+'.txt')\n",
    "\n",
    "print(\"\\t* K fold training and validating...\")\n",
    "test_preds, k_test_probas, dev_probas, dev_labels, best_f1, best_thres = k_fold_cross_val(train_df, test_df, params, k, \n",
    "                                                                                          bert_tokenizer, config.best_model_path, \n",
    "                                                                                          output_path, model_version)\n",
    "dev_preds = (dev_probas[:, 1] > best_thres).type(torch.long)\n",
    "fpr, tpr, thresholds = roc_curve(dev_labels, dev_probas[:, 1], pos_label=1)\n",
    "dev_auc = auc(fpr, tpr)\n",
    "print('dev auc: ',dev_auc)\n",
    "\n",
    "print(\"\\t* Saving dev result...\")\n",
    "with open(os.path.join(config.root_path, 'report/'+scheme_version+'_'+'classification_report.txt'), 'w') as fp:\n",
    "    fp.write(classification_report(dev_labels, dev_preds))\n",
    "    fp.write('\\n')\n",
    "    fp.write('f1-score: {:.4f}'.format(f1_score(dev_labels, dev_preds)))\n",
    "    fp.write(' auc: {:.4f}'.format(dev_auc))\n",
    "\n",
    "train_df.to_csv(os.path.join(config.root_path, 'result/'+scheme_version+'_pred_result.csv'), index=0)\n",
    "\n",
    "print(\"\\t* Predicting...\")\n",
    "test_df['pred'] = test_preds.cpu().numpy()\n",
    "k_test_probas = k_test_probas.cpu().numpy()\n",
    "\n",
    "print(\"\\t* Saving test result...\")\n",
    "# 保存预测结果\n",
    "time_str = '' + time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "test_df[['dialog_id', 'reply_id', 'pred']].to_csv(os.path.join(config.root_path,'submission/'+scheme_version+'_'+time_str+'.csv'),\n",
    "                                                  sep='\\t',\n",
    "                                                  index=0,\n",
    "                                                  header=0)\n",
    "# 保存K折预测概率结果\n",
    "k_test_probas_path = os.path.join(config.root_path, 'result/'+scheme_version+'_'+str(k)+'_test_probas.npz')\n",
    "# if not os.path.exists(k_test_probas_path):\n",
    "np.save(k_test_probas_path, k_test_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7ZmkuLmJBUwW"
   },
   "outputs": [],
   "source": [
    "best_scores = []\n",
    "for fold in range(5):\n",
    "    best_score = torch.load(os.path.join(root_path, 'model/fine-tune/best-fine-tune-V4.5-k'+str(fold)+'.bin'), \n",
    "                            map_location={'cuda:0': 'cuda:1'})['best_score']\n",
    "    best_scores.append(best_score)\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20040982, 0.19991843, 0.19951245, 0.20091086, 0.19924843])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores = np.array(best_scores)\n",
    "# count = sum(best_scores)\n",
    "weighted = best_scores / best_scores.sum()\n",
    "weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = np.array([0.1, 0.4, 0.15, 0.2, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_probas = torch.tensor([[[0.1, 0.9], [0.2, 0.8]], [[0.3,0.7], [0.4, 0.6]], [[0.5,0.5], [0.6, 0.4]], [[0.7,0.3], [0.8, 0.2]], [[0.9,0.1], [0.2, 0.8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 0.9000],\n",
       "         [0.2000, 0.8000]],\n",
       "\n",
       "        [[0.3000, 0.7000],\n",
       "         [0.4000, 0.6000]],\n",
       "\n",
       "        [[0.5000, 0.5000],\n",
       "         [0.6000, 0.4000]],\n",
       "\n",
       "        [[0.7000, 0.3000],\n",
       "         [0.8000, 0.2000]],\n",
       "\n",
       "        [[0.9000, 0.1000],\n",
       "         [0.2000, 0.8000]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = np.expand_dims(np.expand_dims(weighted,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0100, 0.0900],\n",
       "         [0.0200, 0.0800]],\n",
       "\n",
       "        [[0.1200, 0.2800],\n",
       "         [0.1600, 0.2400]],\n",
       "\n",
       "        [[0.0750, 0.0750],\n",
       "         [0.0900, 0.0600]],\n",
       "\n",
       "        [[0.1400, 0.0600],\n",
       "         [0.1600, 0.0400]],\n",
       "\n",
       "        [[0.1350, 0.0150],\n",
       "         [0.0300, 0.1200]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = k_probas * weighted\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4800, 0.5200],\n",
       "        [0.4600, 0.5400]], dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(c, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "V2.0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "customer_churn_analysis",
   "language": "python",
   "name": "customer_churn_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
