{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3254,
     "status": "ok",
     "timestamp": 1604647140528,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "GUwDeFerT89A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, auc, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 2599,
     "status": "ok",
     "timestamp": 1604647140534,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "m8PPhH8ICLaP",
    "outputId": "0d3ad4f2-8dd6-4543-b4c7-4722088f5703"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1950,
     "status": "ok",
     "timestamp": 1604647140539,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "ZihHfS_LT64t"
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from config import device, is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N62ZZGeoT644"
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1604647146335,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "goCLd4xXT644"
   },
   "outputs": [],
   "source": [
    "class QAMatchDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_seq_len_q, max_seq_len_r, mode):\n",
    "        assert mode in ['train', 'dev', 'test']\n",
    "\n",
    "        self.mode = mode\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.max_seq_len_q = max_seq_len_q\n",
    "        self.max_seq_len_r = max_seq_len_r\n",
    "        # self.df = pd.read_csv(file)\n",
    "        # self.seqs, self.seq_masks, self.seq_segments, self.labels = self.get_input(file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        token_seq_1 = self.df.iloc[idx]['question']\n",
    "        token_seq_2 = self.df.iloc[idx]['reply_content']\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            label_tensor = torch.tensor(self.df.iloc[idx]['label'])\n",
    "        else:\n",
    "            label_tensor = None\n",
    "        token_seq_1 = self.tokenizer.tokenize(token_seq_1)\n",
    "        token_seq_2 = self.tokenizer.tokenize(token_seq_2)\n",
    "#         print(\"token_seq_1:\", token_seq_1, \"lens:\", len(token_seq_1))\n",
    "#         print(\"token_seq_2:\", token_seq_2, \"lens:\", len(token_seq_2))\n",
    "\n",
    "        # truncate\n",
    "        if len(token_seq_1) > self.max_seq_len_q:\n",
    "            token_seq_1 = token_seq_1[:self.max_seq_len_q]\n",
    "        if len(token_seq_2) > self.max_seq_len_r:\n",
    "            token_seq_2 = token_seq_2[:self.max_seq_len_r]\n",
    "\n",
    "        seq = [\"[CLS]\"] + token_seq_1 + [\"[SEP]\"] + token_seq_2 + [\"[SEP]\"]\n",
    "        seq = self.tokenizer.convert_tokens_to_ids(seq)\n",
    "\n",
    "        seq_segments = [0] * (len(token_seq_1) + 2) + [1] * (len(token_seq_2) + 1)\n",
    "\n",
    "        return torch.Tensor(seq).type(torch.long), torch.Tensor(seq_segments).type(torch.long), \\\n",
    "            torch.Tensor([len(token_seq_1), len(token_seq_2)]).type(torch.long), label_tensor\n",
    "            \n",
    "\n",
    "    def collate_fn(self, samples):\n",
    "        seqs = [s[0] for s in samples]\n",
    "        seq_segments = [s[1] for s in samples]\n",
    "        seq_lens = torch.stack([s[2] for s in samples])\n",
    "\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            labels = torch.stack([s[3] for s in samples])\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        seqs = pad_sequence(seqs, batch_first=True)\n",
    "        seq_segments = pad_sequence(seq_segments, batch_first=True)\n",
    "\n",
    "        # attention mask处理\n",
    "        seq_masks = torch.zeros(seqs.shape, dtype=torch.long)\n",
    "        seq_masks = seq_masks.masked_fill(seqs != 0, 1)\n",
    "\n",
    "        return seqs, seq_masks, seq_segments, seq_lens, labels\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcQmyLC8T647"
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1604647147355,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "YInuSpqWT648"
   },
   "outputs": [],
   "source": [
    "class BertModelTrain(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(BertModelTrain, self).__init__()        \n",
    "        self.bert_config = BertConfig.from_pretrained(os.path.join(params['pretrained_model_path'], 'config.json'))\n",
    "#         self.bert_config.output_hidden_states = True\n",
    "        self.bert = BertModel.from_pretrained(params['pretrained_model_path'], output_hidden_states=False)\n",
    "        self.bilstm = nn.LSTM(input_size=self.bert_config.hidden_size, \n",
    "                              hidden_size=params['lstm_hidden_size'], \n",
    "                              bidirectional=True, \n",
    "                              batch_first=True)\n",
    "        self.linear = nn.Linear(6 * self.bert_config.hidden_size + 4 * params['num_directions'] * params['lstm_hidden_size'], 1)\n",
    "        self.dropout = nn.Dropout(p=params['dropout_rate'])\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True     # fine-tune，每个参数都要更新\n",
    "\n",
    "    def forward(self, batch_seqs, batch_seq_masks, batch_seq_segments, batch_seq_lens, labels=None):\n",
    "        \"\"\"\n",
    "        :param batch_seqs: input_ids\n",
    "        :param batch_seq_masks: attention_mask\n",
    "        :param batch_seq_segments: token_type_ids\n",
    "        :param batch_seq_lens: (batch, 2)   记录着每一个样本对中，两个文本的真实长度（即不加[CLS]/[SEP]）\n",
    "        :param labels:\n",
    "        :return: outputs: (loss, logits, ...)\n",
    "                 outputs: (logits, ...)\n",
    "        注：\n",
    "        hidden_size: bert中的hidden_size\n",
    "        lstm_hidden_szie: lstm中的hidden_size\n",
    "        \"\"\"\n",
    "        # q_embeddings: last_hidden_state, (batch_size, sequence_length, hidden_size)\n",
    "        # pooler_output : 最后一层[CLS]token的hidden state过一个FN+tanh输出的logits  (batch_size, hidden_size)\n",
    "        q_embeddings, pooler_output = self.bert(input_ids=batch_seqs,\n",
    "                                                attention_mask=batch_seq_masks,\n",
    "                                                token_type_ids=batch_seq_segments)[:2]\n",
    "        # lstm_hidden_size = 512\n",
    "        # lstm_output:t=1到t=seq_len的最后一层的hidden state, shape(batch_first):(batch, seq_len, num_directions * lstm_hidden_size)\n",
    "        # t时刻的token向量= ht(->) concat ht(<-) , shape是lstm_hidden_size*2\n",
    "        lstm_output = self.bilstm(q_embeddings)[0]\n",
    "        \n",
    "        # last layer cls hidden state: (batch_size, hidden_size)\n",
    "        last_cls_hidden_state = q_embeddings[:, 0]\n",
    "        \n",
    "        # lstm层：seq_1和seq_2的句向量embedding（max pooling），均是(batch, num_directions * lstm_hidden_size)\n",
    "        lstm_seq_1_embeddings, lstm_seq_2_embeddings = self.get_seq_embeddings(lstm_output, batch_seq_lens)\n",
    "        # |seq_1 - seq_2|\n",
    "        lstm_seq_gap = torch.abs(lstm_seq_1_embeddings - lstm_seq_2_embeddings)\n",
    "        # seq_1 * seq_2 （对应维度相乘）\n",
    "        lstm_seq_multiple = lstm_seq_1_embeddings * lstm_seq_2_embeddings\n",
    "        \n",
    "        # 倒数第一层：seq_1和seq_2的句向量embedding（max pooling），均是(batch, hidden_size)\n",
    "        last_seq_1_embeddings, last_seq_2_embeddings = self.get_seq_embeddings(q_embeddings, batch_seq_lens)\n",
    "        # |seq_1 - seq_2|\n",
    "        last_seq_gap = torch.abs(last_seq_1_embeddings - last_seq_2_embeddings)\n",
    "        # seq_1 * seq_2 （对应维度相乘）\n",
    "        last_seq_multiple = last_seq_1_embeddings * last_seq_2_embeddings\n",
    "        \n",
    "        # concatenate this four tensor -> (batch_size, 6 * hidden_size + 4 * num_directions * lstm_hidden_size)\n",
    "        x = torch.cat([pooler_output, last_cls_hidden_state, \n",
    "                       last_seq_1_embeddings, last_seq_gap, last_seq_multiple, last_seq_2_embeddings,\n",
    "                       lstm_seq_1_embeddings, lstm_seq_gap, lstm_seq_multiple, lstm_seq_2_embeddings], dim=1)\n",
    "        # dropout\n",
    "        x = self.dropout(x)\n",
    "#         x = nn.functional.dropout(x, p=0.6)\n",
    "        # FC层 -> (batch, 1)\n",
    "        x = self.linear(x)\n",
    "        # sigmoid\n",
    "        output = torch.sigmoid(x)    # (batch_size, 1) 即模型预测每个样本为1的概率\n",
    "\n",
    "        logits = x\n",
    "        proba_0 = 1.0 - output     # (batch_size, 1)\n",
    "        probabilities = torch.cat((proba_0, output), dim=1)   # (batch_size, 2)\n",
    "        if labels is not None:\n",
    "            # 有标签，则返回loss, logits, probabilities\n",
    "            loss = self.loss_fn(output.squeeze(), labels.type(torch.float))\n",
    "            outputs = (loss, logits, probabilities)\n",
    "        else:\n",
    "            # 无标签，则返回logits, probabilities\n",
    "            outputs = (logits, probabilities)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def get_seq_embeddings(self, q_embeddings, batch_seq_lens):\n",
    "        \"\"\"\n",
    "        获取batch中每个样本对中，seq_1和seq_2的\n",
    "        :param q_embeddings: last_hidden_state, (batch_size, sequence_length, hidden_size)\n",
    "        :param batch_seq_lens: (batch, 2)   记录着每一个样本对中，两个文本的真实长度（即不加[CLS]/[SEP]）\n",
    "        \"\"\"\n",
    "        batch_seq_1 = []\n",
    "        batch_seq_2 = []\n",
    "        for batch in range(q_embeddings.shape[0]):\n",
    "            seq_1_end_index = 1 + batch_seq_lens[batch][0]     # # 要加1，否则最后一个字取不到。这里不包含第一句的[SEP]\n",
    "            seq_2_start_index = seq_1_end_index + 1\n",
    "            seq_2_end_index = seq_2_start_index + batch_seq_lens[batch][1]   # 第二句不包括最后的[SEP]\n",
    "            seq_1_embedding = q_embeddings[batch, 1:seq_1_end_index,:]\n",
    "            seq_2_embedding = q_embeddings[batch, seq_2_start_index:seq_2_end_index,:]\n",
    "            batch_seq_1.append(torch.max(seq_1_embedding, dim=0)[0])    # 句向量用max pooling\n",
    "            batch_seq_2.append(torch.max(seq_2_embedding, dim=0)[0])    \n",
    "        batch_seq_1 = torch.stack(batch_seq_1)\n",
    "        batch_seq_2 = torch.stack(batch_seq_2)\n",
    "        return batch_seq_1.to(device), batch_seq_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToLog(path, content):\n",
    "    with open(path, 'a') as fp:\n",
    "        fp.write(content)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCGlq6qBT64_"
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1501,
     "status": "ok",
     "timestamp": 1604647152153,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "feiElGnzT65B"
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, dev_dataloader, params, bert_tokenizer, best_model_path, output_path, fold,\n",
    "          version, checkpoint=None):\n",
    "    # ---------------------- Model definition ---------------------- #\n",
    "    print(\"\\t* Building model...\")\n",
    "    bulid_time = time.time()\n",
    "    model = BertModelTrain(params).to(device)\n",
    "    print(\"\\t* Building model time:{:.4f}s\".format(time.time()-bulid_time))\n",
    "    # ---------------------- Preparation for training -------------- #\n",
    "#     param_optimizer = list(model.named_parameters())\n",
    "    # 这里，指定部分参数不参与权重衰减\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "#     optimizer_grouped_parameters = [{\n",
    "#         'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "#         'weight_decay': params['weight_decay']\n",
    "#     }, {\n",
    "#         'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "#         'weight_decay': 0.0\n",
    "#     }]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': params['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "#     optimizer = AdamW(optimizer_grouped_parameters, lr=params['lr'])\n",
    "    optimizer = Adam(model.parameters(), lr=params['lr'])\n",
    "#     optimizer = SGD(model.parameters(),lr=params['lr'],momentum=params['momentum'], weight_decay=params['l2_weight'])\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.85, patience=params['patience'])\n",
    "    num_training_steps = len(train_dataloader) * params['epochs']\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_training_steps)\n",
    "\n",
    "    best_score = 0.0    # 记录validation最好的结果\n",
    "    best_thres = 0.0\n",
    "    start_epoch = 1\n",
    "    # Data for loss curves plot\n",
    "    epoch_count = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_f1s = []\n",
    "    valid_f1s = []\n",
    "    train_aucs = []\n",
    "    valid_aucs = []\n",
    "    best_model_saved_path = os.path.join(best_model_path, 'best-fine-tune-'+version+'-k'+str(fold)+'.bin')\n",
    "\n",
    "    # Compute loss and accuracy before starting (or resuming) training\n",
    "    # 如果准备start training，这里的valid结果就是预训练BERT（做fine-tune之前）对下游任务的效果\n",
    "    # 如果准备resuming training，这里的valid结果就是上一次fine-tune的结果\n",
    "    valid_loss, valid_accuracy, valid_f1, valid_auc, thres = validate(model, dev_dataloader)\n",
    "    print(\"\\t* Validation loss before training: {:.4f}, accuracy:{:.4f}, \"\n",
    "          \"f1_score: {:.4f}, best_thres: {:.4f}, auc: {:.4f}\".\n",
    "          format(valid_loss, (valid_accuracy * 100), valid_f1, thres, valid_auc))\n",
    "    print(\"\\n\", 20 * \"=\", \"Training Bert model o device: {}\".format(device), 20 * \"=\")\n",
    "\n",
    "    patience_counter = 0\n",
    "    for epoch in range(start_epoch, params['epochs']+1):\n",
    "        print(\"-> Start epoch {}\".format(epoch))\n",
    "        writeToLog(output_path, \"-> Start epoch {}\".format(epoch))\n",
    "        epoch_count.append(epoch)\n",
    "        # train\n",
    "        epoch_time, epoch_loss, epoch_accuracy, epoch_f1, epoch_auc = train_for_one_epoch(model,\n",
    "                                                                                          train_dataloader,\n",
    "                                                                                          optimizer,\n",
    "                                                                                          scheduler,\n",
    "                                                                                          params['max_gradient_norm'])\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_f1s.append(epoch_f1)\n",
    "        train_aucs.append(epoch_auc)\n",
    "        print(\"-> Training time:{:.4f}s, loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, auc: {:.4f}\".\n",
    "              format(epoch_time, epoch_loss, epoch_accuracy*100, epoch_f1, epoch_auc))\n",
    "        writeToLog(output_path, \"-> Training time:{:.4f}s, loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, auc: {:.4f}\".\n",
    "              format(epoch_time, epoch_loss, epoch_accuracy*100, epoch_f1, epoch_auc))\n",
    "        \n",
    "        # validation\n",
    "        valid_loss, valid_accuracy, valid_f1, valid_auc, thres = validate(model, dev_dataloader)\n",
    "        print(\"-> Validation loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, best_thres: {:.4f}, auc: {:.4f}\".\n",
    "              format(valid_loss, valid_accuracy * 100, valid_f1, thres, valid_auc))\n",
    "        writeToLog(output_path, \"-> Validation loss: {:.4f}, accuracy: {:.4f}%, f1_score: {:.4f}, best_thres: {:.4f}, auc: {:.4f}\".\n",
    "              format(valid_loss, valid_accuracy * 100, valid_f1, thres, valid_auc))\n",
    "        \n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_f1s.append(valid_f1)\n",
    "        valid_aucs.append(valid_auc)\n",
    "#         scheduler.step(valid_loss)\n",
    "        \n",
    "        if valid_auc <= best_score:\n",
    "            patience_counter += 1\n",
    "        else:\n",
    "            best_score = valid_auc\n",
    "            best_thres = thres\n",
    "            patience_counter = 0\n",
    "            best_model_saved_path = os.path.join(best_model_path, 'best-fine-tune-'+version+'-k'+str(fold)+'.bin')\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"best_score\": best_score,    # k fold时以valid auc来看每折的模型的能力，从而对最终的预测结果进行加权平均\n",
    "                \"best_thres\": best_thres,\n",
    "                \"epochs_count\": epoch_count,\n",
    "                \"train_losses\": train_losses,\n",
    "                \"valid_losses\": valid_losses\n",
    "            }, best_model_saved_path)\n",
    "\n",
    "        if patience_counter >= params['early_stoping']:\n",
    "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "            break\n",
    "            \n",
    "    if patience_counter != 0:\n",
    "        # 如果最后一个epoch不是最好的模型，则读取之前的最好的模型\n",
    "        best_checkpoint = torch.load(best_model_saved_path)\n",
    "        model.load_state_dict(best_checkpoint['model'])\n",
    "#     return model, best_score, epoch_count, train_losses, train_f1s, train_aucs, valid_losses, valid_f1s, valid_aucs\n",
    "    return model, best_score\n",
    "\n",
    "def train_for_one_epoch(model, dataloader, optimizer, scheduler, max_gradient_norm):\n",
    "    model.train()\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0   # 记录整个epoch的累加loss\n",
    "    correct_count = 0.0\n",
    "    batch_avg_time = 0.0 # 记录该epoch平均batch花费时间\n",
    "    all_preds = []\n",
    "    all_pred_probas = []\n",
    "    all_labels = []\n",
    "\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    for batch_index, data in enumerate(tqdm_dataloader):\n",
    "        batch_start_time = time.time()\n",
    "        if is_cuda:\n",
    "            data = [t.to(device) for t in data if t is not None]\n",
    "        # 梯度置零\n",
    "        optimizer.zero_grad()\n",
    "        seqs, seq_masks, seq_segments, seq_lens, labels = data\n",
    "        outputs = model(seqs, seq_masks, seq_segments, seq_lens, labels)\n",
    "        # 回传梯度\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        probabilities = outputs[2]\n",
    "        # probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        loss.backward()\n",
    "        # 梯度裁剪\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = torch.argmax(probabilities, dim=1)\n",
    "        correct_count = correct_count + (pred == labels).sum().item()\n",
    "        batch_avg_time += time.time() - batch_start_time\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_pred_probas.append(probabilities.detach().cpu())\n",
    "\n",
    "        description = \"Batch num: {}. Avg. batch proc. time: {:.4f}s, loss: {:.4f}\".\\\n",
    "            format(batch_index+1, batch_avg_time/(batch_index+1), running_loss/(batch_index+1))\n",
    "        tqdm_dataloader.set_description(description)\n",
    "#         del data\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "    all_labels = torch.cat(all_labels)    # 把每个batch的labels平铺成一维tensor (samples, )\n",
    "    all_preds = torch.cat(all_preds)      # 把每个batch的preds平铺成一维tensor (samples, )\n",
    "    all_pred_probas = torch.cat(all_pred_probas) # 把每个batch的probas平铺成tensor (samples, 2)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_pred_probas[:, 1], pos_label=1)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = correct_count / len(dataloader.dataset)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    epoch_auc = auc(fpr, tpr)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    return epoch_time, epoch_loss, epoch_accuracy, epoch_f1, epoch_auc\n",
    "#     return epoch_time, epoch_loss, epoch_accuracy, 0, epoch_auc\n",
    "\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0  # 记录整个epoch的累加loss\n",
    "    correct_count = 0.0\n",
    "    # all_preds = []\n",
    "    all_labels = []\n",
    "    all_pred_probas = []\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "\n",
    "    # Deactivate autograd for evaluation\n",
    "    with torch.no_grad():   # 必须加这个，减少显存的使用\n",
    "        for batch_index, data in enumerate(tqdm_dataloader):\n",
    "            if is_cuda:\n",
    "                data = [t.to(device) for t in data if t is not None]\n",
    "\n",
    "            seqs, seq_masks, seq_segments, seq_lens, labels = data\n",
    "            outputs = model(seqs, seq_masks, seq_segments, seq_lens, labels)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            probabilities = outputs[2]\n",
    "            # probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # _, pred = torch.max(logits, dim=1)\n",
    "\n",
    "            # correct_count = correct_count + (pred == labels).sum().item()\n",
    "            # all_preds.append(pred.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_pred_probas.append(probabilities.cpu())\n",
    "            \n",
    "#             del data\n",
    "#             torch.cuda.empty_cache()\n",
    "                    \n",
    "    all_labels = torch.cat(all_labels)  # 把每个batch的labels平铺成一维tensor shape: (samples, )\n",
    "    # all_preds = torch.cat(all_preds)  # 把每个batch的preds平铺成一维tensor shape: (samples, )\n",
    "    all_pred_probas = torch.cat(all_pred_probas)  # 把每个batch的probas变成tensor（原来是[tensor, tensor, ...]）\n",
    "\n",
    "\n",
    "    # best_f1, best_thres = search_f1(all_labels, all_pred_probas[:, 1])\n",
    "    # all_preds = (all_pred_probas[:, 1] > best_thres).type(torch.long)\n",
    "    all_preds = torch.argmax(all_pred_probas, dim=1)\n",
    "    correct_count = (all_preds == all_labels).sum().item()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_pred_probas[:, 1], pos_label=1)\n",
    "\n",
    "    valid_loss = running_loss / len(dataloader)\n",
    "    valid_acc = correct_count / len(dataloader.dataset)\n",
    "    valid_f1 = f1_score(all_labels, all_preds)\n",
    "    # valid_f1 = best_f1\n",
    "    valid_auc = auc(fpr, tpr)\n",
    "    best_thres = 0\n",
    "    return valid_loss, valid_acc, valid_f1, valid_auc, best_thres\n",
    "    # return valid_loss, valid_acc, 0, 0\n",
    "    \n",
    "def search_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_true: 一维tensor\n",
    "    :param y_pred: 一维tensor，y_pred[i]表示第i个样本在label为1上的预测概率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    best_score = 0.0\n",
    "    best_thres = 0.0\n",
    "    for i in range(30, 70):\n",
    "        thres = i / 100\n",
    "        y_pred_bin = (y_pred > thres)   # 大于thres的为1，小于thres的为0\n",
    "        # print(\"y_pred_bin shape:\", y_pred_bin.shape)\n",
    "        score = f1_score(y_true, y_pred_bin)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thres = thres\n",
    "\n",
    "    return best_score, best_thres\n",
    "    \n",
    "def get_pred_probas(model, dataloader, is_test=False):\n",
    "    model.eval()\n",
    "    probas = None\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            # 将所有tensors移到GPU上\n",
    "            if is_cuda:\n",
    "                data = [t.to(device) for t in data if t is not None]\n",
    "                \n",
    "            if is_test:\n",
    "                seqs, seq_masks, seq_segments, seq_lens = data[:4]\n",
    "            else:\n",
    "                seqs, seq_masks, seq_segments, seq_lens, labels = data\n",
    "                all_labels.append(labels)\n",
    "            outputs = model(seqs,\n",
    "                            seq_masks,\n",
    "                            seq_segments,\n",
    "                            seq_lens)\n",
    "            logits = outputs[0]\n",
    "            probabilities = outputs[1]   # (batch, 2)\n",
    "\n",
    "            if probas is None:\n",
    "                probas = probabilities\n",
    "            else:\n",
    "                # 将每个batch的预测结果拼接起来\n",
    "                probas = torch.cat([probas, probabilities])\n",
    "    if is_test:\n",
    "        return probas.cpu()\n",
    "    all_labels = torch.cat(all_labels)  # (len, )\n",
    "    return probas.cpu(), all_labels.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPlXyVxaT65G"
   },
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1604647152686,
     "user": {
      "displayName": "梁寓杰",
      "photoUrl": "",
      "userId": "14609683328165856029"
     },
     "user_tz": -480
    },
    "id": "bPHMPZyOT65H"
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_val(train_df, test_df, params, k, bert_tokenizer, best_model_path, output_path, version):\n",
    "    kf = KFold(n_splits=k)\n",
    "    test_dataset = QAMatchDataset(test_df, bert_tokenizer, params['max_seq_len_q'], params['max_seq_len_r'], mode='test')\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=512, num_workers=3, collate_fn=test_dataset.collate_fn)\n",
    "    dev_labels = []\n",
    "    dev_probas = []\n",
    "    k_test_probas = []\n",
    "    k_best_scores = []\n",
    "    for fold, (train_idxs, dev_idxs) in enumerate(kf.split(train_df)):\n",
    "        print(\"\\t* Start \"+str(fold)+\" fold\")\n",
    "        writeToLog(output_path, \"\\t* Start \"+str(fold)+\" fold\")\n",
    "#         dev_labels.extend(train_df.iloc[dev_idxs]['label'].tolist())\n",
    "        # ---------------------- Data loading -------------------------- #\n",
    "        print(\"\\t* Building dataset...\")\n",
    "        train_dataset = QAMatchDataset(train_df.iloc[train_idxs], bert_tokenizer, params['max_seq_len_q'], params['max_seq_len_r'], 'train')\n",
    "        dev_dataset = QAMatchDataset(train_df.iloc[dev_idxs], bert_tokenizer, params['max_seq_len_q'], params['max_seq_len_r'], 'dev')\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'], num_workers=3,\n",
    "                                      collate_fn=train_dataset.collate_fn)\n",
    "        dev_dataloader = DataLoader(dev_dataset, batch_size=512, num_workers=3,\n",
    "                                    collate_fn=dev_dataset.collate_fn)\n",
    "        best_model_fold_path = os.path.join(best_model_path, 'best-fine-tune-'+version+'-k'+str(fold)+'.bin')\n",
    "        checkpoint = None\n",
    "        if not(os.path.exists(best_model_fold_path)):\n",
    "            # 若没有\n",
    "            \n",
    "            model, best_score = train(train_dataloader, dev_dataloader, params, bert_tokenizer, best_model_path, output_path, \n",
    "                                      fold, version, checkpoint=None)\n",
    "        else:\n",
    "            checkpoint = torch.load(best_model_fold_path)\n",
    "            model = BertModelTrain(params).to(device)\n",
    "            model.load_state_dict(checkpoint['model'])\n",
    "            best_score = checkpoint['best_score']\n",
    "        k_best_scores.append(best_score)\n",
    "        \n",
    "        fold_dev_proba, dev_label = get_pred_probas(model, dev_dataloader)\n",
    "        for idx, proba in zip(dev_idxs, fold_dev_proba):\n",
    "            train_df.loc[idx, 'proba_0'] = proba[0].item()\n",
    "            train_df.loc[idx, 'proba_1'] = proba[1].item()\n",
    "        fold_test_proba = get_pred_probas(model, test_dataloader, is_test=True)\n",
    "        \n",
    "        dev_labels.append(dev_label)\n",
    "        dev_probas.append(fold_dev_proba)  # (k, len(dev_idxs), 2)\n",
    "        k_test_probas.append(fold_test_proba) # (k, len(test_dataset), 2)\n",
    "#         model.to(torch.device('cpu'))\n",
    "        del model, train_dataloader, dev_dataloader, checkpoint\n",
    "        torch.cuda.empty_cache() \n",
    "        time.sleep(5)\n",
    "    \n",
    "    dev_labels = torch.cat(dev_labels)  # (len(train_df),)      # 把每一折的验证集的label拼接，得到整个训练集的label\n",
    "    dev_probas = torch.cat(dev_probas)  # (len(train_df), 2)    # 把每一折的验证集的预测结果拼接，得到整个训练集的预测结果\n",
    "    \n",
    "    k_test_probas = torch.stack(k_test_probas) # (k, len(test_dataset), 2)， 只是把[tensor, tensor, ... ]转为tensor\n",
    "#     test_probas = torch.mean(k_test_probas, dim=0)  # (len(test_dataset), 2)  取每一折的平均\n",
    "\n",
    "    # k折模型加权融合\n",
    "    k_best_scores = np.array(k_best_scores)              \n",
    "    k_weights = k_best_scores / k_best_scores.sum()             # (k,)\n",
    "    k_weights = np.expand_dims(np.expand_dims(k_weights,1),1)   # (k, 1, 1)\n",
    "    print('k_best_score :', k_best_scores)\n",
    "    print('k weights :', k_weights)\n",
    "    k_test_probas = k_test_probas * k_weights               # 广播机制，使得每个模型预测的概率乘上该模型的权重 (k, len(test_dataset), 2)\n",
    "    test_probas = torch.sum(k_test_probas, dim=0)           # 求和\n",
    "    # search f1\n",
    "    best_f1, best_thres = search_f1(dev_labels, dev_probas[:, 1])\n",
    "    print(best_f1, best_thres)\n",
    "    test_preds = (test_probas[:, 1] > best_thres).type(torch.long)\n",
    "    \n",
    "    # 不用search f1\n",
    "    # test_preds = torch.argmax(test_probas, dim=1) \n",
    "    return test_preds, k_test_probas, dev_probas, dev_labels, best_f1, best_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kf4-Fr6T65Y"
   },
   "source": [
    "## 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qs0l9xpYT65Y",
    "outputId": "817beebe-3e63-4b30-ccc9-1b73ee5458f7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* K fold training and validating...\n",
      "\t* Start 0 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:11.2278s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:40<00:00,  2.28s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 0.7197, accuracy:75.5733, f1_score: 0.0000, best_thres: 0.0000, auc: 0.5579\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3729s, loss: 0.3674: 100%|██████████| 1439/1439 [09:02<00:00,  2.83it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:542.6291s, loss: 0.3674, accuracy: 84.5978%, f1_score: 0.6670, auc: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2670, accuracy: 88.8348%, f1_score: 0.7729, best_thres: 0.0000, auc: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3699s, loss: 0.2158: 100%|██████████| 1439/1439 [08:58<00:00,  2.62it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:538.5128s, loss: 0.2158, accuracy: 91.4780%, f1_score: 0.8278, auc: 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2776, accuracy: 89.1012%, f1_score: 0.7929, best_thres: 0.0000, auc: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3941s, loss: 0.1348: 100%|██████████| 1439/1439 [09:35<00:00,  2.58it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:575.2229s, loss: 0.1348, accuracy: 95.0484%, f1_score: 0.9017, auc: 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3002, accuracy: 90.1436%, f1_score: 0.8088, best_thres: 0.0000, auc: 0.9484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3765s, loss: 0.0871: 100%|██████████| 1439/1439 [09:08<00:00,  2.70it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:548.3905s, loss: 0.0871, accuracy: 96.9508%, f1_score: 0.9396, auc: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3137, accuracy: 90.7575%, f1_score: 0.8179, best_thres: 0.0000, auc: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3713s, loss: 0.0592: 100%|██████████| 1439/1439 [09:00<00:00,  2.78it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:540.2462s, loss: 0.0592, accuracy: 97.9093%, f1_score: 0.9586, auc: 0.9967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.35s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3957, accuracy: 91.3134%, f1_score: 0.8239, best_thres: 0.0000, auc: 0.9455\n",
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3708s, loss: 0.0469: 100%|██████████| 1439/1439 [08:59<00:00,  2.78it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:539.7977s, loss: 0.0469, accuracy: 98.4392%, f1_score: 0.9690, auc: 0.9978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.34s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3818, accuracy: 91.5798%, f1_score: 0.8282, best_thres: 0.0000, auc: 0.9526\n",
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3733s, loss: 0.0389: 100%|██████████| 1439/1439 [09:03<00:00,  2.74it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:543.2008s, loss: 0.0389, accuracy: 98.7462%, f1_score: 0.9751, auc: 0.9984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3712, accuracy: 91.7304%, f1_score: 0.8329, best_thres: 0.0000, auc: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3704s, loss: 0.0308: 100%|██████████| 1439/1439 [08:58<00:00,  2.76it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:539.0560s, loss: 0.0308, accuracy: 99.0097%, f1_score: 0.9803, auc: 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.34s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4259, accuracy: 91.6956%, f1_score: 0.8336, best_thres: 0.0000, auc: 0.9530\n",
      "-> Start epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3705s, loss: 0.0270: 100%|██████████| 1439/1439 [08:59<00:00,  2.75it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:539.6955s, loss: 0.0270, accuracy: 99.1226%, f1_score: 0.9826, auc: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.34s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3877, accuracy: 92.1126%, f1_score: 0.8397, best_thres: 0.0000, auc: 0.9554\n",
      "-> Start epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3698s, loss: 0.0216: 100%|██████████| 1439/1439 [08:58<00:00,  2.86it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:538.4773s, loss: 0.0216, accuracy: 99.2992%, f1_score: 0.9861, auc: 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4310, accuracy: 91.9852%, f1_score: 0.8400, best_thres: 0.0000, auc: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3731s, loss: 0.0181: 100%|██████████| 1439/1439 [09:02<00:00,  2.71it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:542.9087s, loss: 0.0181, accuracy: 99.3977%, f1_score: 0.9880, auc: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.37s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4404, accuracy: 92.0199%, f1_score: 0.8372, best_thres: 0.0000, auc: 0.9565\n",
      "-> Start epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3749s, loss: 0.0149: 100%|██████████| 1439/1439 [09:05<00:00,  2.67it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:545.6332s, loss: 0.0149, accuracy: 99.4730%, f1_score: 0.9895, auc: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.35s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.5080, accuracy: 91.9041%, f1_score: 0.8398, best_thres: 0.0000, auc: 0.9542\n",
      "-> Start epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3734s, loss: 0.0135: 100%|██████████| 1439/1439 [09:03<00:00,  2.86it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:543.1933s, loss: 0.0135, accuracy: 99.5077%, f1_score: 0.9902, auc: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4624, accuracy: 92.1937%, f1_score: 0.8442, best_thres: 0.0000, auc: 0.9565\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 1 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:7.4417s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:40<00:00,  2.30s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 0.9208, accuracy:24.9247, f1_score: 0.3941, best_thres: 0.0000, auc: 0.5323\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3852s, loss: 0.3643: 100%|██████████| 1439/1439 [09:20<00:00,  2.76it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:560.5345s, loss: 0.3643, accuracy: 84.3256%, f1_score: 0.6617, auc: 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:40<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2902, accuracy: 87.7693%, f1_score: 0.7561, best_thres: 0.0000, auc: 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3831s, loss: 0.2323: 100%|██████████| 1439/1439 [09:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:557.5900s, loss: 0.2323, accuracy: 90.9162%, f1_score: 0.8152, auc: 0.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2693, accuracy: 89.8772%, f1_score: 0.7980, best_thres: 0.0000, auc: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3814s, loss: 0.1511: 100%|██████████| 1439/1439 [09:14<00:00,  2.76it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:555.0512s, loss: 0.1511, accuracy: 94.4489%, f1_score: 0.8891, auc: 0.9802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2713, accuracy: 90.9775%, f1_score: 0.8128, best_thres: 0.0000, auc: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3798s, loss: 0.0983: 100%|██████████| 1439/1439 [09:12<00:00,  2.80it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:552.7950s, loss: 0.0983, accuracy: 96.5947%, f1_score: 0.9323, auc: 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:40<00:00,  2.31s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3358, accuracy: 91.0702%, f1_score: 0.8179, best_thres: 0.0000, auc: 0.9500\n",
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3872s, loss: 0.0669: 100%|██████████| 1439/1439 [09:23<00:00,  2.61it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:563.9622s, loss: 0.0669, accuracy: 97.7240%, f1_score: 0.9549, auc: 0.9957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.35s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3492, accuracy: 91.0354%, f1_score: 0.8213, best_thres: 0.0000, auc: 0.9506\n",
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3870s, loss: 0.0486: 100%|██████████| 1439/1439 [09:23<00:00,  2.67it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:563.6329s, loss: 0.0486, accuracy: 98.3581%, f1_score: 0.9674, auc: 0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4058, accuracy: 91.8114%, f1_score: 0.8311, best_thres: 0.0000, auc: 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4062s, loss: 0.0414: 100%|██████████| 1439/1439 [09:54<00:00,  2.57it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:594.5953s, loss: 0.0414, accuracy: 98.6419%, f1_score: 0.9730, auc: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3796, accuracy: 91.6145%, f1_score: 0.8323, best_thres: 0.0000, auc: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4039s, loss: 0.0306: 100%|██████████| 1439/1439 [09:51<00:00,  2.55it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:591.2922s, loss: 0.0306, accuracy: 98.9257%, f1_score: 0.9786, auc: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.36s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4201, accuracy: 91.0007%, f1_score: 0.8243, best_thres: 0.0000, auc: 0.9523\n",
      "-> Start epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4050s, loss: 0.0270: 100%|██████████| 1439/1439 [09:52<00:00,  2.52it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:592.8185s, loss: 0.0270, accuracy: 99.1052%, f1_score: 0.9822, auc: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:41<00:00,  2.37s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4524, accuracy: 91.6030%, f1_score: 0.8331, best_thres: 0.0000, auc: 0.9492\n",
      "-> Start epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4068s, loss: 0.0233: 100%|██████████| 1439/1439 [09:55<00:00,  2.57it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:595.4750s, loss: 0.0233, accuracy: 99.2124%, f1_score: 0.9843, auc: 0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4641, accuracy: 91.4408%, f1_score: 0.8306, best_thres: 0.0000, auc: 0.9514\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 2 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:12.5361s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.46s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 2.3258, accuracy:25.1564, f1_score: 0.4020, best_thres: 0.0000, auc: 0.4619\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4067s, loss: 0.3782: 100%|██████████| 1439/1439 [09:54<00:00,  2.47it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:595.1355s, loss: 0.3782, accuracy: 84.5544%, f1_score: 0.6739, auc: 0.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2672, accuracy: 88.8927%, f1_score: 0.7788, best_thres: 0.0000, auc: 0.9381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4051s, loss: 0.2065: 100%|██████████| 1439/1439 [09:52<00:00,  2.49it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:592.9643s, loss: 0.2065, accuracy: 91.8892%, f1_score: 0.8352, auc: 0.9635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2806, accuracy: 90.0973%, f1_score: 0.7965, best_thres: 0.0000, auc: 0.9423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4065s, loss: 0.1284: 100%|██████████| 1439/1439 [09:55<00:00,  2.51it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:595.3150s, loss: 0.1284, accuracy: 95.0918%, f1_score: 0.9017, auc: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2913, accuracy: 90.3289%, f1_score: 0.8179, best_thres: 0.0000, auc: 0.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3905s, loss: 0.0833: 100%|██████████| 1439/1439 [09:31<00:00,  2.40it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:571.2711s, loss: 0.0833, accuracy: 97.0203%, f1_score: 0.9404, auc: 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.47s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3195, accuracy: 91.1281%, f1_score: 0.8284, best_thres: 0.0000, auc: 0.9495\n",
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3901s, loss: 0.0616: 100%|██████████| 1439/1439 [09:30<00:00,  2.66it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:570.7680s, loss: 0.0616, accuracy: 97.8369%, f1_score: 0.9567, auc: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3003, accuracy: 91.0702%, f1_score: 0.8292, best_thres: 0.0000, auc: 0.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4027s, loss: 0.0472: 100%|██████████| 1439/1439 [09:49<00:00,  2.61it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:589.6823s, loss: 0.0472, accuracy: 98.3379%, f1_score: 0.9667, auc: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.46s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3820, accuracy: 91.3829%, f1_score: 0.8289, best_thres: 0.0000, auc: 0.9492\n",
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4020s, loss: 0.0389: 100%|██████████| 1439/1439 [09:48<00:00,  2.59it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:588.5362s, loss: 0.0389, accuracy: 98.6940%, f1_score: 0.9739, auc: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.45s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3701, accuracy: 91.5219%, f1_score: 0.8326, best_thres: 0.0000, auc: 0.9495\n",
      "-> Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4048s, loss: 0.0311: 100%|██████████| 1439/1439 [09:52<00:00,  2.45it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:592.3823s, loss: 0.0311, accuracy: 98.9257%, f1_score: 0.9785, auc: 0.9989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:44<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.4368, accuracy: 92.0662%, f1_score: 0.8415, best_thres: 0.0000, auc: 0.9493\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 3 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:12.6269s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.49s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 0.6532, accuracy:74.8291, f1_score: 0.0000, best_thres: 0.0000, auc: 0.5317\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3928s, loss: 0.3624: 100%|██████████| 1439/1439 [09:34<00:00,  2.63it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:574.2233s, loss: 0.3624, accuracy: 84.7546%, f1_score: 0.6682, auc: 0.8786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2632, accuracy: 89.0768%, f1_score: 0.7811, best_thres: 0.0000, auc: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3951s, loss: 0.2124: 100%|██████████| 1439/1439 [09:37<00:00,  2.62it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:577.8898s, loss: 0.2124, accuracy: 91.5274%, f1_score: 0.8277, auc: 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2527, accuracy: 90.3510%, f1_score: 0.8178, best_thres: 0.0000, auc: 0.9527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3936s, loss: 0.1257: 100%|██████████| 1439/1439 [09:35<00:00,  2.62it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:575.6380s, loss: 0.1257, accuracy: 95.4394%, f1_score: 0.9089, auc: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.47s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2847, accuracy: 91.3703%, f1_score: 0.8268, best_thres: 0.0000, auc: 0.9504\n",
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3940s, loss: 0.0825: 100%|██████████| 1439/1439 [09:35<00:00,  2.63it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:576.0913s, loss: 0.0825, accuracy: 97.0986%, f1_score: 0.9420, auc: 0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.46s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3023, accuracy: 91.0460%, f1_score: 0.8252, best_thres: 0.0000, auc: 0.9506\n",
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3932s, loss: 0.0580: 100%|██████████| 1439/1439 [09:34<00:00,  2.65it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:574.8097s, loss: 0.0580, accuracy: 97.9760%, f1_score: 0.9595, auc: 0.9968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:43<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3225, accuracy: 91.4977%, f1_score: 0.8302, best_thres: 0.0000, auc: 0.9499\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "\t* Start 4 fold\n",
      "\t* Building dataset...\n",
      "\t* Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Building model time:12.3212s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.33s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation loss before training: 0.8157, accuracy:74.4585, f1_score: 0.0000, best_thres: 0.0000, auc: 0.5224\n",
      "\n",
      " ==================== Training Bert model o device: cuda ====================\n",
      "-> Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.4026s, loss: 0.3933: 100%|██████████| 1439/1439 [09:48<00:00,  2.47it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:588.7756s, loss: 0.3933, accuracy: 83.6079%, f1_score: 0.6256, auc: 0.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3090, accuracy: 87.4667%, f1_score: 0.7364, best_thres: 0.0000, auc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3946s, loss: 0.2413: 100%|██████████| 1439/1439 [09:36<00:00,  2.52it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:576.5042s, loss: 0.2413, accuracy: 90.3460%, f1_score: 0.8009, auc: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2721, accuracy: 89.9571%, f1_score: 0.7929, best_thres: 0.0000, auc: 0.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3948s, loss: 0.1481: 100%|██████████| 1439/1439 [09:36<00:00,  2.50it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:576.9905s, loss: 0.1481, accuracy: 94.4144%, f1_score: 0.8873, auc: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.2765, accuracy: 90.7796%, f1_score: 0.8182, best_thres: 0.0000, auc: 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3941s, loss: 0.0913: 100%|██████████| 1439/1439 [09:35<00:00,  2.50it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:576.1085s, loss: 0.0913, accuracy: 96.8119%, f1_score: 0.9360, auc: 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3118, accuracy: 90.5016%, f1_score: 0.8233, best_thres: 0.0000, auc: 0.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3952s, loss: 0.0693: 100%|██████████| 1439/1439 [09:37<00:00,  2.46it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:577.7246s, loss: 0.0693, accuracy: 97.6864%, f1_score: 0.9536, auc: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.32s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3375, accuracy: 90.5479%, f1_score: 0.8215, best_thres: 0.0000, auc: 0.9481\n",
      "-> Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3936s, loss: 0.0515: 100%|██████████| 1439/1439 [09:35<00:00,  2.48it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:575.2621s, loss: 0.0515, accuracy: 98.2539%, f1_score: 0.9649, auc: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.30s/it]\n",
      "  0%|          | 0/1439 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3536, accuracy: 91.5672%, f1_score: 0.8357, best_thres: 0.0000, auc: 0.9458\n",
      "-> Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch num: 1439. Avg. batch proc. time: 0.3934s, loss: 0.0431: 100%|██████████| 1439/1439 [09:34<00:00,  2.51it/s]\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time:575.0555s, loss: 0.0431, accuracy: 98.5551%, f1_score: 0.9710, auc: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:42<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validation loss: 0.3707, accuracy: 90.8607%, f1_score: 0.8266, best_thres: 0.0000, auc: 0.9457\n",
      "-> Early stopping: patience limit reached, stopping...\n",
      "k_best_score : [0.95665302 0.95536636 0.95472462 0.95265619 0.94878024]\n",
      "k weights : [[[0.20063272]]\n",
      "\n",
      " [[0.20036288]]\n",
      "\n",
      " [[0.20022829]]\n",
      "\n",
      " [[0.19979449]]\n",
      "\n",
      " [[0.19898161]]]\n",
      "0.8291517323775388 0.66\n",
      "dev auc:  0.9468933740671792\n",
      "\t* Saving dev result...\n",
      "\t* Predicting...\n",
      "\t* Saving test result...\n"
     ]
    }
   ],
   "source": [
    "model_version = 'FFTPD-5fold-V5.0.3'     # 模型版本\n",
    "scheme_version = 'FFTPD-5fold-V5.0.3'     # 方案版本\n",
    "# train_df = pd.read_csv(train_all_path)\n",
    "train_df = pd.read_csv(config.augmented_V0204_path)\n",
    "# test_df = pd.read_csv(test_path)\n",
    "# train_df = pd.read_csv(train_V0_path)\n",
    "test_df = pd.read_csv(config.test_V0_path)\n",
    "k = 5\n",
    "\n",
    "params = {\n",
    "    'batch_size': 24,\n",
    "    'epochs': 20,\n",
    "    'lr': 2e-05,\n",
    "    'l2_weight':0.0005,\n",
    "    'weight_decay': 0.01,\n",
    "    'dropout_rate': 0.5,\n",
    "    'momentum': 0.8,\n",
    "    'early_stoping':3,\n",
    "    'patience': 2,\n",
    "    'lstm_hidden_size': 768,\n",
    "    'num_directions': 2,\n",
    "    'max_seq_len_q': 24,\n",
    "    'max_seq_len_r': 52,\n",
    "    'max_gradient_norm': 10.0,\n",
    "    'pretrained_model_path': config.pretrained_roberta_wwm_ext_large_path, \n",
    "}\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(os.path.join(params['pretrained_model_path'], 'vocab.txt'))\n",
    "output_path = os.path.join(config.root_path, 'output/'+scheme_version+'.txt')\n",
    "\n",
    "print(\"\\t* K fold training and validating...\")\n",
    "test_preds, k_test_probas, dev_probas, dev_labels, best_f1, best_thres = k_fold_cross_val(train_df, test_df, params, k, \n",
    "                                                                                          bert_tokenizer, config.best_model_path, \n",
    "                                                                                          output_path, model_version)\n",
    "dev_preds = (dev_probas[:, 1] > best_thres).type(torch.long)\n",
    "fpr, tpr, thresholds = roc_curve(dev_labels, dev_probas[:, 1], pos_label=1)\n",
    "dev_auc = auc(fpr, tpr)\n",
    "print('dev auc: ',dev_auc)\n",
    "\n",
    "print(\"\\t* Saving dev result...\")\n",
    "with open(os.path.join(config.root_path, 'report/'+scheme_version+'_'+'classification_report.txt'), 'w') as fp:\n",
    "    fp.write(classification_report(dev_labels, dev_preds))\n",
    "    fp.write('\\n')\n",
    "    fp.write('f1-score: {:.4f}'.format(f1_score(dev_labels, dev_preds)))\n",
    "    fp.write(' auc: {:.4f}'.format(dev_auc))\n",
    "\n",
    "# 保存每一折对验证集的预测概率（0和1都有）\n",
    "train_df.to_csv(os.path.join(config.root_path, 'result/'+scheme_version+'_pred_result.csv'), index=0)\n",
    "\n",
    "print(\"\\t* Predicting...\")\n",
    "test_df['pred'] = test_preds.cpu().numpy()\n",
    "k_test_probas = k_test_probas.cpu().numpy()\n",
    "\n",
    "print(\"\\t* Saving test result...\")\n",
    "# 保存预测结果\n",
    "time_str = '' + time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "test_df[['dialog_id', 'reply_id', 'pred']].to_csv(os.path.join(config.root_path,'submission/'+scheme_version+'_'+time_str+'.csv'),\n",
    "                                                  sep='\\t',\n",
    "                                                  index=0,\n",
    "                                                  header=0)\n",
    "# 保存K折预测概率结果\n",
    "k_test_probas_path = os.path.join(config.root_path, 'result/'+scheme_version+'_'+str(k)+'_test_probas.npz')\n",
    "if not os.path.exists(k_test_probas_path):\n",
    "    np.save(k_test_probas_path, k_test_probas)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "V2.0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "customer_churn_analysis",
   "language": "python",
   "name": "customer_churn_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
